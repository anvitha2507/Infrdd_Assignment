{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the dataframes for training\n",
    "df_train = pd.DataFrame()\n",
    "\n",
    "# Combine the dataframes\n",
    "for filename in listdir(\"dataset\\\\dataset\\\\train\\\\boxes_transcripts_labels\\\\\"):\n",
    "    df_temp = pd.read_csv(\"dataset\\\\dataset\\\\train\\\\boxes_transcripts_labels\\\\\" + filename, sep = \",\", header = None)\n",
    "    df_temp.columns = ['start_index', 'end_index', 'x_top_left', 'y_top_left', 'x_bottom_right', 'y_bottom_right','transcript','field']\n",
    "    #df_temp_trimmed = df_temp.loc[df_temp['field'] != 'OTHER']\n",
    "\n",
    "    df_train = pd.concat([df_train, df_temp], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we build the model and the preprocessing functions based on our analysis\n",
    "def Feature_Engineering(df):\n",
    "    df['x_center'] = df[['x_top_left', 'x_bottom_right']].mean(axis=1)\n",
    "    df['y_center'] = df[['y_top_left', 'y_bottom_right']].mean(axis=1)\n",
    "    df['index_len'] = df['end_index'] - df['start_index']\n",
    "\n",
    "    # We select 5 features told to us by RFECV and the label\n",
    "    df = df[['start_index', 'end_index', 'x_center', 'y_center', 'index_len', 'field']]\n",
    "\n",
    "    return df\n",
    "\n",
    "def X_y_split(df):\n",
    "    y = df[['field']]\n",
    "    X = df[['start_index', 'end_index', 'x_center', 'y_center', 'index_len']]\n",
    "    return X,y\n",
    "\n",
    "def Hierarchical_Training(df, model1, model2):\n",
    "    df1 = Feature_Engineering(df)\n",
    "    df2 = df1.copy()\n",
    "\n",
    "    # For 1st model, we convert relevant columns as \"not other\"  & We reduce the number of \"OTHER\" columns to reduce skewness\n",
    "    df1.loc[df[\"field\"] != \"OTHER\", \"field\"] = 'NOT_OTHER'\n",
    "    rus = RandomUnderSampler(random_state=0, sampling_strategy=0.5)\n",
    "    X1,y1 = X_y_split(df1)\n",
    "    resampled_X1, resampled_y1 = rus.fit_resample(X1,y1)\n",
    "\n",
    "    model1 = model1.fit(resampled_X1, resampled_y1.values.ravel())\n",
    "\n",
    "\n",
    "    # For 2nd model, we simply drop all rows with 'OTHER' as label\n",
    "    df2 = df2.loc[df2['field'] != 'OTHER']\n",
    "    X2,y2 = X_y_split(df2)\n",
    "\n",
    "    model2 = model2.fit(X2, y2.values.ravel())\n",
    "\n",
    "    return model1, model2\n",
    "\n",
    "\n",
    "def Testing(df, model1, model2):\n",
    "    df1 = Feature_Engineering(df)\n",
    "    X_test, y_test = X_y_split(df1)\n",
    "\n",
    "    main_pred = []\n",
    "\n",
    "    # Making separate y to compare for model1 and 2\n",
    "    y_test1 = y_test.copy()\n",
    "    y_test1.loc[y_test1[\"field\"] != \"OTHER\", \"field\"] = 'NOT_OTHER'\n",
    "\n",
    "    y_pred1 = model1.predict(X_test)\n",
    "    y_pred2 = model2.predict(X_test)\n",
    "\n",
    "\n",
    "    cm_other = confusion_matrix(y_test1, y_pred1)\n",
    "    \n",
    "    # Combining the two results to get the original result.\n",
    "    for i in range(len(y_pred1)):\n",
    "        if y_pred1[i] != 'OTHER': main_pred.append(y_pred2[i])\n",
    "        else: main_pred.append(y_pred1[i])\n",
    "    \n",
    "    cm_main = confusion_matrix(y_test, main_pred)\n",
    "\n",
    "    return cm_main, cm_other\n",
    "\n",
    "def Testing_with_pred(df, model1, model2):\n",
    "    df['x_center'] = df[['x_top_left', 'x_bottom_right']].mean(axis=1)\n",
    "    df['y_center'] = df[['y_top_left', 'y_bottom_right']].mean(axis=1)\n",
    "    df['index_len'] = df['end_index'] - df['start_index']\n",
    "\n",
    "    # We select 5 features told to us by RFECV\n",
    "    df = df[['start_index', 'end_index', 'x_center', 'y_center', 'index_len']]\n",
    "\n",
    "    main_pred = []\n",
    "\n",
    "    y_pred1 = model1.predict(df)\n",
    "    y_pred2 = model2.predict(df)\n",
    "\n",
    "    for i in range(len(y_pred1)):\n",
    "        if y_pred1[i] != 'OTHER': main_pred.append(y_pred2[i])\n",
    "        else: main_pred.append(y_pred1[i])\n",
    "    \n",
    "    return main_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200 # Obtained from model analysis\n",
    "\n",
    "model1 = RandomForestClassifier(n_estimators = n, verbose=1)\n",
    "model2 = RandomForestClassifier(n_estimators = n, verbose=1)\n",
    "\n",
    "model1, model2 = Hierarchical_Training(df_train, model1, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing just one df to check accuracy\n",
    "df_test = pd.read_csv(\"dataset\\\\dataset\\\\val_w_ann\\\\boxes_transcripts_labels\\\\0b55f878-9dc7-478b-9bba-342056684452_document-1_page-1.tsv\", sep = ',', header = None)\n",
    "df_test.columns = ['start_index', 'end_index', 'x_top_left', 'y_top_left', 'x_bottom_right', 'y_bottom_right','transcript', 'field']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_main, cm_other = Testing(df_test, model1, model2)\n",
    "\n",
    "# sns.heatmap(cm_other/np.sum(cm_other), annot=True, fmt='.2%')\n",
    "\n",
    "cm_sum = 0\n",
    "for i in range(len(cm_main)):\n",
    "    cm_sum += cm_main[i][i]\n",
    "acc = cm_sum/np.sum(cm_main)\n",
    "print('accuracy for entire data: ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final predictions of testing data\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for filename in listdir(\"dataset\\\\dataset\\\\val\\\\boxes_transcripts\\\\\"):\n",
    "    df = pd.read_csv(\"dataset\\\\dataset\\\\val\\\\boxes_transcripts\\\\\" + filename, sep = \",\", header = None)\n",
    "    df.columns = ['start_index', 'end_index', 'x_top_left', 'y_top_left', 'x_bottom_right', 'y_bottom_right','transcript']\n",
    "\n",
    "    df_test = df.copy()\n",
    "\n",
    "    y_pred = Testing_with_pred(df_test, model1, model2)\n",
    "    ydf = pd.DataFrame(y_pred, columns=['field'])\n",
    "    out = pd.concat([df, ydf], axis=1)\n",
    "    # out.to_csv(\"dataset\\\\dataset\\\\result\\\\boxes_transcripts_labels\\\\\" + filename, sep = \",\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
